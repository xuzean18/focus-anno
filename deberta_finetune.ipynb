{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8657197,"sourceType":"datasetVersion","datasetId":5175896}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers datasets evaluate seqeval accelerate -U\nfrom datasets import load_dataset,load_metric, Dataset, Features, ClassLabel\nfrom transformers import DebertaForTokenClassification, DebertaTokenizerFast, Trainer, TrainingArguments, DataCollatorForTokenClassification\nimport torch\nimport numpy as np\nimport pandas as pd\nimport csv\nimport evaluate\nfrom sklearn.metrics import confusion_matrix\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-11T11:42:41.508128Z","iopub.execute_input":"2024-06-11T11:42:41.508512Z","iopub.status.idle":"2024-06-11T11:43:22.605184Z","shell.execute_reply.started":"2024-06-11T11:42:41.508478Z","shell.execute_reply":"2024-06-11T11:43:22.603896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optional block to disable unnecessary wandb login\n! pip install -q wandb\nimport wandb\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:43:22.607073Z","iopub.execute_input":"2024-06-11T11:43:22.607720Z","iopub.status.idle":"2024-06-11T11:43:36.570788Z","shell.execute_reply.started":"2024-06-11T11:43:22.607685Z","shell.execute_reply":"2024-06-11T11:43:36.569536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_path = '/kaggle/input/qc1a-dataset/train.tsv'\neval_data_path = '/kaggle/input/qc1a-dataset/val.tsv'\ntest_data_path = '/kaggle/input/qc1a-dataset/test.tsv'\nsave_path = '/kaggle/working/'\n\ntrain_data = pd.read_csv(train_data_path, sep='\\t')\neval_data = pd.read_csv(eval_data_path, sep='\\t')\ntest_data = pd.read_csv(test_data_path, sep='\\t')\n\ndef str2list(token):\n    if type(token) is float:\n        return []\n    token = token[1:-1]\n    splitted = [word[1:-1] for word in token.split(\", \")]\n    return splitted\n\ntrain_data[\"tokens\"] = train_data[\"tokens\"].map(str2list)\ntrain_data[\"ner_tags\"] = train_data[\"ner_tags\"].map(str2list)\neval_data[\"tokens\"] = eval_data[\"tokens\"].map(str2list)\neval_data[\"ner_tags\"] = eval_data[\"ner_tags\"].map(str2list)\ntest_data[\"tokens\"] = test_data[\"tokens\"].map(str2list)\ntest_data[\"ner_tags\"] = test_data[\"ner_tags\"].map(str2list)\n\ntrain_dataset = Dataset.from_pandas(train_data)\neval_dataset = Dataset.from_pandas(eval_data)\ntest_dataset = Dataset.from_pandas(test_data)\n\nclassmap = ClassLabel(num_classes=3, names=['O', 'B-focus', 'I-focus'])\n\ntrain_dataset = train_dataset.map(lambda y: {\"ner_tags\": classmap.str2int(y[\"ner_tags\"])})\neval_dataset = eval_dataset.map(lambda y: {\"ner_tags\": classmap.str2int(y[\"ner_tags\"])})\ntest_dataset = test_dataset.map(lambda y: {\"ner_tags\": classmap.str2int(y[\"ner_tags\"])})\n\nlabel_names = dict(zip([0, 1, 2], ['O', 'B-focus', 'I-focus']))\nid2label = {i: classmap.int2str(i) for i in range(classmap.num_classes)}\nlabel2id = {c: classmap.str2int(c) for c in classmap.names}\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:43:36.572225Z","iopub.execute_input":"2024-06-11T11:43:36.572901Z","iopub.status.idle":"2024-06-11T11:43:56.737750Z","shell.execute_reply.started":"2024-06-11T11:43:36.572856Z","shell.execute_reply":"2024-06-11T11:43:56.736476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_checkpoints = [\"microsoft/deberta-base\"]\n\nfor model_checkpoint in model_checkpoints:\n    tokenizer = DebertaTokenizerFast.from_pretrained(model_checkpoint, add_prefix_space=True)\n    model = DebertaForTokenClassification.from_pretrained(\n        model_checkpoint,\n        id2label={i: classmap.int2str(i) for i in range(classmap.num_classes)},\n        label2id={c: classmap.str2int(c) for c in classmap.names},\n        finetuning_task=\"ner\"\n    )\n\n    def tokenize_and_align_labels(examples):\n        tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n        labels = []\n        for i, label in enumerate(examples[\"ner_tags\"]):\n            word_ids = tokenized_inputs.word_ids(batch_index=i)\n            previous_word_idx = None\n            label_ids = []\n            for word_idx in word_ids:\n                if word_idx is None:\n                    label_ids.append(-100)\n                elif word_idx != previous_word_idx:\n                    label_ids.append(label[word_idx])\n                else:\n                    label_ids.append(-100)\n                previous_word_idx = word_idx\n            labels.append(label_ids)\n        tokenized_inputs[\"labels\"] = labels\n        return tokenized_inputs\n\n    train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n    eval_dataset = eval_dataset.map(tokenize_and_align_labels, batched=True)\n    test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n\n    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\n    metric = evaluate.load(\"seqeval\")\n\n    def compute_metrics(eval_preds):\n        logits, labels = eval_preds\n        predictions = np.argmax(logits, axis=-1)\n        true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n        true_predictions = [\n            [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n            for prediction, label in zip(predictions, labels)\n        ]\n        all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n\n        flattened_true = [label for sublist in true_labels for label in sublist]\n        flattened_pred = [label for sublist in true_predictions for label in sublist]\n\n        labels_set = list(set(flattened_true + flattened_pred))\n\n        cm = confusion_matrix(flattened_true, flattened_pred, labels=labels_set)\n\n        per_class_accuracies = cm.diagonal() / cm.sum(axis=1)\n        class_accuracies = {label: per_class_accuracies[idx] for idx, label in enumerate(labels_set)}\n\n        return {\n            \"overall_precision\": all_metrics[\"overall_precision\"],\n            \"overall_recall\": all_metrics[\"overall_recall\"],\n            \"overall_f1\": all_metrics[\"overall_f1\"],\n            \"overall_accuracy\": all_metrics[\"overall_accuracy\"],\n            \"per_class_accuracies\": class_accuracies,\n            \"entity_metrics\": {\n                entity: {\n                    \"precision\": metrics[\"precision\"],\n                    \"recall\": metrics[\"recall\"],\n                    \"f1\": metrics[\"f1\"],\n                    \"number\": metrics[\"number\"]\n                }\n                for entity, metrics in all_metrics.items()\n                if entity not in [\"overall_precision\", \"overall_recall\", \"overall_f1\", \"overall_accuracy\"]\n            }\n        }\n\n    training_args = TrainingArguments(\n        output_dir=save_path,\n        num_train_epochs=3,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        learning_rate=5e-5,\n        weight_decay=0.01,\n        evaluation_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n\n    predictions, labels, _ = trainer.predict(test_dataset)\n    predictions = np.argmax(predictions, axis=-1)\n\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    errors = []\n    for i, (true_label, true_prediction) in enumerate(zip(true_labels, true_predictions)):\n        for j, (label, prediction) in enumerate(zip(true_label, true_prediction)):\n            if label != prediction:\n                errors.append({\n                    \"index\": i,\n                    \"tokens\": test_data.iloc[i][\"tokens\"],\n                    \"token\": test_data.iloc[i][\"tokens\"][j],\n                    \"true_label\": label,\n                    \"predicted_label\": prediction\n                })\n\n    errors_df = pd.DataFrame(errors)\n    errors_df.to_csv(f\"{save_path}/errors.tsv\", sep='\\t', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:43:56.740676Z","iopub.execute_input":"2024-06-11T11:43:56.741154Z","iopub.status.idle":"2024-06-11T11:44:11.561173Z","shell.execute_reply.started":"2024-06-11T11:43:56.741114Z","shell.execute_reply":"2024-06-11T11:44:11.559632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(save_path + \"model/\")\ntokenizer.save_pretrained(save_path + \"tokenizer/\")","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:44:11.562606Z","iopub.status.idle":"2024-06-11T11:44:11.563041Z","shell.execute_reply.started":"2024-06-11T11:44:11.562818Z","shell.execute_reply":"2024-06-11T11:44:11.562849Z"},"trusted":true},"execution_count":null,"outputs":[]}]}